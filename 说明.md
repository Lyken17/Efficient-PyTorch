# Efficient-PyTorch
我使用PyTorch训练大型数据集的最佳实践。

# 速度概述
通过遵循这些提示，当在ImageNet上训练ResNet-50时，我们可以使用PyTorch达到**〜730张图像/秒**。 根据[Tensorflow]（https://www.tensorflow.org/performance/benchmarks）和[MXNet]（https://github.com/apache/incubator-mxnet/tree/master/example/image-classification），表现仍然具有竞争力。
```
Epoch: [0][430/5005]    Time 0.409 (0.405)      Data 626.6 (728.0)      Loss 6.8381 (6.9754)    Error@1 100.000 (99.850) Error@5 99.609 (99.259)
Epoch: [0][440/5005]    Time 0.364 (0.404)      Data 704.2 (727.9)      Loss 6.8506 (6.9725)    Error@1 100.000 (99.851) Error@5 99.609 (99.258)
Epoch: [0][450/5005]    Time 0.350 (0.403)      Data 730.7 (727.3)      Loss 6.8846 (6.9700)    Error@1 100.000 (99.847) Error@5 99.609 (99.258)
Epoch: [0][460/5005]    Time 0.357 (0.402)      Data 716.8 (727.4)      Loss 6.9129 (6.9680)    Error@1 100.000 (99.849) Error@5 99.609 (99.256)
Epoch: [0][470/5005]    Time 0.346 (0.401)      Data 740.8 (727.4)      Loss 6.8574 (6.9657)    Error@1 100.000 (99.850) Error@5 98.828 (99.249)
Epoch: [0][480/5005]    Time 0.425 (0.400)      Data 601.8 (727.3)      Loss 6.8467 (6.9632)    Error@1 100.000 (99.849) Error@5 99.609 (99.239)
Epoch: [0][490/5005]    Time 0.358 (0.399)      Data 715.2 (727.2)      Loss 6.8319 (6.9607)    Error@1 100.000 (99.848) Error@5 99.609 (99.232)
Epoch: [0][500/5005]    Time 0.347 (0.399)      Data 737.4 (726.9)      Loss 6.8426 (6.9583)    Error@1 99.609 (99.843)  Error@5 98.047 (99.220)
Epoch: [0][510/5005]    Time 0.346 (0.398)      Data 740.5 (726.7)      Loss 6.8245 (6.9561)    Error@1 100.000 (99.839) Error@5 99.609 (99.211)
Epoch: [0][520/5005]    Time 0.350 (0.452)      Data 730.7 (724.0)      Loss 6.8270 (6.9538)    Error@1 99.609 (99.834)  Error@5 97.656 (99.193)
Epoch: [0][530/5005]    Time 0.340 (0.450)      Data 752.9 (724.4)      Loss 6.8149 (6.9516)    Error@1 100.000 (99.832) Error@5 98.047 (99.183)
```

# 效率要点
现在，大多数框架都将“ CUDNN”作为后端。 如果不进行特殊优化，则推断时间在各个框架之间都是相似的。 为了优化培训时间，我们专注于其他方面，例如：
## Data Loader
默认组合`datasets.ImageFolder` +`data.DataLoader`不足以进行大规模分类。 根据我的经验，即使我升级到Samsung 960 Pro（读取3.5 GB / s，写入2.0 GB / s），整个训练管道仍困在磁盘I / O上。 

造成这种情况的原因是**不相称的小块**读取缓慢。 为了进行优化，我们需要将较小的JPEG图像转储到较大的二进制文件中。 TensorFlow有自己的`TFRecord`并且MXNet使用`recordIO`。 除了这两个以外，还有其他选项，例如“ hdf5”，“ pth”，“ n5”，“ lmdb”等。在这里，我选择“ lmdb”是因为
1. TFRecord是一个私有协议，很难破解。 `RecordIO`的文档令人困惑，并且没有提供干净的python API。
2. `hdf5``pth``n5`尽管具有简单的类似于json的API，但需要将整个文件放入内存中。 当您使用像imagenet这样的大型数据集时，这不是实践。
## Data Parallel

由nn.DataParallel提供支持的PyTorch的默认数据并行无效！ 首先，因为Python的GIL，多线程并未完全利用所有内核[torch / nn / parallel / parallel_apply.py＃47]（https://github.com/pytorch/pytorch/blob/master/torch/nn /parallel/parallel_apply.py#L47）。 其次，`DataParallel`的集体计划是在`cuda：0`上收集所有结果。 这会导致工作负载不平衡，有时甚至会导致OOM，尤其是您正在运行细分模型时。
`nn.DistributedDataParllel` provides a more elegant solution: Instead of launching call from different threads, it starts with multiple processes (no GIL) and assigns a balanced workload for all GPUs. 

（正在进行）详细的脚本和实验编号。
